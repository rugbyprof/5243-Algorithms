# üß† Algorithms Study Guide  

**Or: How to Stop Treating Big-O Like a Vibe Check**

- If this document feels long, good.  
- If it feels interconnected, *excellent*.  
- If you‚Äôre hoping to memorize your way through it ‚Äî I regret to inform you that algorithms notice.

This handout is doing **three jobs at once**:

1. A **refresher** (you‚Äôve seen these parts before‚Ä¶ allegedly)
2. A **concept map** (how things actually relate)
3. A **reality check** (performance is not a suggestion)

---

## Part 0 ‚Äî Ground Rules (Read Before Skipping Ahead)

- **Data structures do not do anything by themselves**
- **Algorithms without a container are just ideas**
- **Big-O is not about speed ‚Äî it‚Äôs about growth**
- If you say ‚Äúit‚Äôs fast enough,‚Äù you have already lost the argument

---

## Part 1 ‚Äî Refresher (The Backbone Stuff You‚Äôre Supposed to Know)

### Stacks
**Definition:**  
LIFO ‚Äî *Last In, First Out*

**Canonical operations:**  
- `push`
- `pop`
- `top / peek`

**Implementations:**
- Array-based (vector)
- List-based (linked list)

**Complexity:**
- Push: **O(1)**
- Pop: **O(1)**

**Invariants (say this out loud):**  
> The only accessible element is the most recently added one.

Stacks are not clever.  
They are **predictable**, which is why they are everywhere.

---

### Queues
**Definition:**  
FIFO ‚Äî *First In, First Out*

**Canonical operations:**  
- `enqueue`
- `dequeue`

**Implementations:**
- Circular array
- Linked list

**Complexity (done right):**
- Enqueue: **O(1)**
- Dequeue: **O(1)**

**Reality check:**  
Using a plain array and shifting elements = **algorithmic malpractice**

---

### List-Based vs Array-Based (The First Real Tradeoff)

| Feature                | Array-Based | List-Based                     |
| ---------------------- | ----------- | ------------------------------ |
| Memory locality        | Excellent   | Terrible                       |
| Random access          | O(1)        | O(n)                           |
| Insert/remove (middle) | O(n)        | O(1) *if you‚Äôre already there* |
| Cache friendly         | Yes         | No                             |

#### **Translation:**  

Arrays are fast *when structure is stable*.  
Lists are flexible *when movement is frequent*.

---

## Part 2 ‚Äî Iteration vs Recursion (This Will Come Back Later)

### Iteration
- Explicit control
- Explicit state
- Uses loops
- Usually stack-safe

### Recursion
- Implicit stack
- Elegant
- Dangerous if misused
- Tree-shaped problems **want** recursion

**Key insight:**  
> Recursion isn‚Äôt magic ‚Äî it‚Äôs a stack you didn‚Äôt write.

---

## Part 3 ‚Äî Trees (Graphs That Behave)

### Tree Definition
A tree is:
- A **connected**
- **Acyclic**
- Directed or undirected graph
- With **n ‚àí 1 edges** for **n nodes**

If you have more edges, congratulations ‚Äî it‚Äôs a graph now.

---

### Trees as Graphs
- Trees ‚äÇ Graphs
- All trees are graphs
- Not all graphs are trees
- Trees impose **structure**
- Graphs allow **chaos**

---

### Core Tree Properties

- **Root**
- **Parent / Child**
- **Leaf**
- **Height**: longest root-to-leaf path
- **Path**: sequence of connected nodes

**Balanced tree (definition that matters):**
> Height grows logarithmically with number of nodes.

---

### Tree Complexity (Binary Trees)

| Operation | Balanced | Worst Case |
| --------- | -------- | ---------- |
| Search    | O(log n) | O(n)       |
| Insert    | O(log n) | O(n)       |
| Delete    | O(log n) | O(n)       |

That ‚Äúworst case‚Äù is a linked list wearing a disguise.

---

### Tree Traversals (You Will Be Asked This)

- **Preorder** (Root, Left, Right)
- **Inorder** (Left, Root, Right)
- **Postorder** (Left, Right, Root)

**Why they exist:**
- Preorder ‚Üí structure first
- Inorder ‚Üí sorted order (BST only)
- Postorder ‚Üí safe deletion

**Critical exam question:**  
> Which traversal(s) let you reconstruct a binary tree?

Answer:
- Inorder **plus** Preorder  
- Inorder **plus** Postorder  
- Inorder alone is useless (fight me)

---

### Deleting a Node (BST Reality)

Cases:
1. Leaf ‚Üí delete
2. One child ‚Üí promote child
3. Two children ‚Üí chaos

**Solution tools:**
- Inorder successor (smallest right subtree)
- Inorder predecessor (largest left subtree)

This is where people stop hand-waving and start sweating.

---

## Part 4 ‚Äî Array-Based Trees (When Shape Matters)

### Why Sparse Trees Are a Problem
- Array indices explode
- Memory waste
- Cache sadness

### When Array-Based Trees Are Good
- **Complete trees**
- **Binary heaps**
- When structure is guaranteed

### Index Formulas (0-based)

- Parent: `(i - 1) / 2`
- Left child: `2i + 1`
- Right child: `2i + 2`

If you memorize nothing else ‚Äî memorize this.

---

## Part 5 ‚Äî Binary Search (The Gateway Algorithm)

### Preconditions
- Data must be **sorted**
- Random access required

### Complexity
- Time: **O(log n)**
- Space: **O(1)** iterative, **O(log n)** recursive

### Why It Matters
- Pairs perfectly with arrays
- Mirrors BST behavior
- Teaches divide-and-conquer thinking

Binary search on unsorted data is **confidence without justification**.

---

## Part 6 ‚Äî Graphs (Where Structure Goes to Die)

### Formal Definition
`G = (V, E)`

- `V`: vertices
- `E`: edges

### Core Concepts
- Directed vs Undirected
- Weighted edges
- Degree
  - In-degree
  - Out-degree
- Source / Sink
- Cycles
- Paths

### Representations

| Representation   | Space    | Traversal        |
| ---------------- | -------- | ---------------- |
| Adjacency Matrix | O(V¬≤)    | Fast edge lookup |
| Adjacency List   | O(V + E) | Fast traversal   |

Sparse graph ‚Üí list  
Dense graph ‚Üí matrix  

---

### BFS vs DFS (Not the Same, Stop Saying That)

**Breadth-First Search**
- Uses a **queue**
- Level-by-level
- Shortest path (unweighted)

**Depth-First Search**
- Uses a **stack**
- Goes deep first
- Cycle detection
- Topological flavor

Both:
- Time: **O(V + E)**

---

### Graph Types You‚Äôre Expected to Recognize
- Sparse
- Dense
- Fully connected
- Bipartite
- Forest (a bunch of trees pretending not to know each other)

---

## Part 7 ‚Äî The Big Picture (This Is the Point)

### The Progression (On Purpose)

1. Stacks & Queues  
2. Trees  
3. Binary Trees (structure rules)
4. Binary Search Trees (structure + ordering algorithm)
5. Graphs (trees with commitment issues)
6. Array vs List tradeoffs
7. Binary Search (algorithm meets structure)
8. Heaps (priority queues done right)

This is not random.  
This is scaffolding.

---

## Part 8 ‚Äî Heaps (Where It All Pays Off)

### Heap Properties
- Complete binary tree
- Parent dominates children (min or max)
- **No total ordering**

### Why Heaps Matter
They implement **priority queues** efficiently.

### Complexity

| Operation | Complexity |
| --------- | ---------- |
| Insert    | O(log n)   |
| Remove    | O(log n)   |
| Heapify   | O(n)       |

Yes ‚Äî heapify is **O(n)**.  
No ‚Äî that is not a typo.  
Yes ‚Äî you should be suspicious until you understand why.

---

### Why Arrays Work So Well Here
- Complete tree
- No wasted indices
- Perfect cache behavior

This is where theory and hardware stop fighting.

---

## Final Takeaway (Read This Again Before Exams)

- Algorithms don‚Äôt exist in isolation
- Containers shape performance
- Structure determines complexity
- Big-O tells you **how badly things scale when you‚Äôre wrong**

If something feels ‚Äúobvious‚Äù now, good.  
It wasn‚Äôt obvious when this field was invented.

That means you‚Äôre learning it **correctly**.
